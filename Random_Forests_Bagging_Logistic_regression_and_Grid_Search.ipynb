{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "X = df.drop('Outcome',axis=1)\n",
    "y = df['Outcome']\n",
    "X_col=X.columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100,\n",
       "                  oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit 100 trees and bag them\n",
    "tree = DecisionTreeClassifier()\n",
    "bag = BaggingClassifier(tree, n_estimators=100, random_state=0,oob_score=True)\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7337662337662337 Oob Accuracy: 0.758957654723127\n"
     ]
    }
   ],
   "source": [
    "y_pred=bag.predict(X_test)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred),'Oob Accuracy:',bag.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(max_iter=1000),\n",
       "                  n_estimators=100, oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000)\n",
    "bag = BaggingClassifier(lr, n_estimators=100, random_state=0,oob_score=True)\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7817589576547231"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=bag.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7662337662337663 Oob Accuracy: 0.755700325732899\n"
     ]
    }
   ],
   "source": [
    "#Fit random forests\n",
    "clf=RandomForestClassifier(random_state=0,n_estimators=100,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred),'Oob Accuracy:',clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Trees</th>\n",
       "      <th>Oob Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.7345276872964169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.755700325732899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.762214983713355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.7638436482084691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.7736156351791531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.7736156351791531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>350.0</td>\n",
       "      <td>0.7785016286644951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400.0</td>\n",
       "      <td>0.7719869706840391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>450.0</td>\n",
       "      <td>0.7719869706840391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.7736156351791531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_Trees        Oob Accuracy\n",
       "0             50.0  0.7345276872964169\n",
       "1            100.0   0.755700325732899\n",
       "2            150.0   0.762214983713355\n",
       "3            200.0  0.7638436482084691\n",
       "4            250.0  0.7736156351791531\n",
       "5            300.0  0.7736156351791531\n",
       "6            350.0  0.7785016286644951\n",
       "7            400.0  0.7719869706840391\n",
       "8            450.0  0.7719869706840391\n",
       "9            500.0  0.7736156351791531"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try different numbers of trees\n",
    "Oob_Accuracy=[]\n",
    "for i in np.linspace(start = 50, stop = 500, num = 10):\n",
    "    clf=RandomForestClassifier(random_state=0,n_estimators=int(i),oob_score=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    Oob_Accuracy.append([i,np.array(clf.oob_score_)])\n",
    "df = pd.DataFrame(Oob_Accuracy,columns=['Number_of_Trees','Oob Accuracy'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9baed3fc70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(df['Number_of_Trees'].values,df['Oob Accuracy'].values,label = 'Oob Accuracy')\n",
    "ax.set_xlabel('Number_of_Trees')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.tick_params(axis='x', labelsize=8)\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Although we picked 350, we could have picked a bigger number. Higher Number of trees do not lead to overfitting\n",
    "clf=RandomForestClassifier(random_state=0,n_estimators=350,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Features</th>\n",
       "      <th>Oob Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7719869706840391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7785016286644951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.7899022801302932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7785016286644951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.7736156351791531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7736156351791531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.7654723127035831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.7785016286644951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_Features        Oob Accuracy\n",
       "0                   1  0.7719869706840391\n",
       "1                   2  0.7785016286644951\n",
       "2                   3  0.7899022801302932\n",
       "3                   4  0.7785016286644951\n",
       "4                   5  0.7736156351791531\n",
       "5                   6  0.7736156351791531\n",
       "6                   7  0.7654723127035831\n",
       "7                   8  0.7785016286644951"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try different numbers of features at each split (default is sqrt(p) where p is the number of features)\n",
    "Oob_Accuracy=[]\n",
    "for i in range(1,9):\n",
    "    clf=RandomForestClassifier(random_state=0,n_estimators=350,max_features=i,oob_score=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    Oob_Accuracy.append([i,np.array(clf.oob_score_)])\n",
    "df = pd.DataFrame(Oob_Accuracy,columns=['Number_of_Features','Oob Accuracy'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0,n_estimators=350,max_features=3,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Features</th>\n",
       "      <th>Oob Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.754071661237785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.758957654723127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.7687296416938111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.760586319218241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.754071661237785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7719869706840391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.758957654723127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.760586319218241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number_of_Features        Oob Accuracy\n",
       "0                   1   0.754071661237785\n",
       "1                   2   0.758957654723127\n",
       "2                   3  0.7687296416938111\n",
       "3                   4   0.760586319218241\n",
       "4                   5   0.754071661237785\n",
       "5                   6  0.7719869706840391\n",
       "6                   7   0.758957654723127\n",
       "7                   8   0.760586319218241"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oob_Accuracy=[]\n",
    "for i in range(1,9):\n",
    "    clf=RandomForestClassifier(random_state=0,n_estimators=350,max_features=i,oob_score=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    Oob_Accuracy.append([i,np.array(clf.oob_score_)])\n",
    "df = pd.DataFrame(Oob_Accuracy,columns=['Number_of_Features','Oob Accuracy'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0,n_estimators=350,max_features=6,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 200, 300, 400, 500, 600],\n",
       " 'max_features': [1, 2, 3, 4, 5, 6, 7, 8]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0)\n",
    "# number of trees in random forest\n",
    "n_estimators = [100,200,300,400,500,600]\n",
    "# number of features at every split\n",
    "max_features = [1,2,3,4,5,6,7,8]\n",
    "# create grid\n",
    "params = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " }\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 4, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Grid search of parameters\n",
    "clf_grid = GridSearchCV(estimator = clf, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='accuracy',n_jobs = -1)\n",
    "# Fit the model\n",
    "clf_grid.fit(X_train, y_train)\n",
    "# print results\n",
    "print(clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0,n_estimators=300,max_features=4,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Grid search of parameters\n",
    "clf_grid = GridSearchCV(estimator = clf, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='accuracy',n_jobs = -1)\n",
    "# Fit the model\n",
    "clf_grid.fit(X_train, y_train)\n",
    "# print results\n",
    "print(clf_grid.best_params_)\n",
    "#The results are different :) This will always happen because there is variability due to a change in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0,n_estimators=100,max_features=6,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 1, 'n_estimators': 600}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 2, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 2, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 1, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0)\n",
    "# number of trees in random forest\n",
    "n_estimators = [100,200,300,400,500,600]\n",
    "# number of features at every split\n",
    "max_features = [1,2,3,4,5,6,7,8]\n",
    "# create grid\n",
    "params = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " }\n",
    "#Instead of one test set we will use cross validation, please note that both parameter selection and \n",
    "#the test performance is computed via cross validation (a nested cross-validation) \n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "CVErrors=[]\n",
    "for train_index, validation_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[validation_index], \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[validation_index]\n",
    "    # Grid search of parameters\n",
    "    clf_grid = GridSearchCV(estimator = clf, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='accuracy',n_jobs = -1)\n",
    "    # Fit the model\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    # print results\n",
    "    print(clf_grid.best_params_)\n",
    "    #After finding best parameters fit the model\n",
    "    clf=RandomForestClassifier(**clf_grid.best_params_)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    #Test the performance on the test set\n",
    "    CVErrors.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8051948051948052,\n",
       " 0.7467532467532467,\n",
       " 0.7532467532467533,\n",
       " 0.7973856209150327,\n",
       " 0.6993464052287581]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7603853662677192"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CVErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "{'max_features': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Grid search of parameters\n",
    "clf_grid = GridSearchCV(estimator = clf, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='roc_auc',n_jobs = -1)\n",
    "# Fit the model\n",
    "clf_grid.fit(X_train, y_train)\n",
    "# print results\n",
    "print(clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87, 13],\n",
       "       [23, 31]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0,n_estimators=200,max_features=2,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97 , 0.03 ],\n",
       "       [0.91 , 0.09 ],\n",
       "       [0.89 , 0.11 ],\n",
       "       [0.615, 0.385],\n",
       "       [0.56 , 0.44 ],\n",
       "       [0.7  , 0.3  ],\n",
       "       [0.985, 0.015],\n",
       "       [0.96 , 0.04 ],\n",
       "       [0.255, 0.745],\n",
       "       [0.965, 0.035],\n",
       "       [0.765, 0.235],\n",
       "       [0.965, 0.035],\n",
       "       [0.35 , 0.65 ],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.985, 0.015],\n",
       "       [0.54 , 0.46 ],\n",
       "       [0.815, 0.185],\n",
       "       [0.475, 0.525],\n",
       "       [0.925, 0.075],\n",
       "       [0.44 , 0.56 ],\n",
       "       [0.165, 0.835],\n",
       "       [0.87 , 0.13 ],\n",
       "       [0.765, 0.235],\n",
       "       [0.83 , 0.17 ],\n",
       "       [0.465, 0.535],\n",
       "       [0.495, 0.505],\n",
       "       [0.585, 0.415],\n",
       "       [0.93 , 0.07 ],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.725, 0.275],\n",
       "       [0.945, 0.055],\n",
       "       [0.91 , 0.09 ],\n",
       "       [0.77 , 0.23 ],\n",
       "       [0.835, 0.165],\n",
       "       [0.23 , 0.77 ],\n",
       "       [0.28 , 0.72 ],\n",
       "       [0.62 , 0.38 ],\n",
       "       [0.14 , 0.86 ],\n",
       "       [0.83 , 0.17 ],\n",
       "       [0.735, 0.265],\n",
       "       [0.905, 0.095],\n",
       "       [0.43 , 0.57 ],\n",
       "       [0.68 , 0.32 ],\n",
       "       [0.75 , 0.25 ],\n",
       "       [0.525, 0.475],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.73 , 0.27 ],\n",
       "       [0.735, 0.265],\n",
       "       [0.645, 0.355],\n",
       "       [0.21 , 0.79 ],\n",
       "       [0.995, 0.005],\n",
       "       [0.865, 0.135],\n",
       "       [0.25 , 0.75 ],\n",
       "       [0.545, 0.455],\n",
       "       [0.77 , 0.23 ],\n",
       "       [0.73 , 0.27 ],\n",
       "       [0.83 , 0.17 ],\n",
       "       [0.985, 0.015],\n",
       "       [0.295, 0.705],\n",
       "       [0.35 , 0.65 ],\n",
       "       [0.935, 0.065],\n",
       "       [0.71 , 0.29 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.99 , 0.01 ],\n",
       "       [0.205, 0.795],\n",
       "       [0.905, 0.095],\n",
       "       [0.99 , 0.01 ],\n",
       "       [0.185, 0.815],\n",
       "       [0.99 , 0.01 ],\n",
       "       [0.72 , 0.28 ],\n",
       "       [0.43 , 0.57 ],\n",
       "       [0.775, 0.225],\n",
       "       [0.68 , 0.32 ],\n",
       "       [0.5  , 0.5  ],\n",
       "       [0.495, 0.505],\n",
       "       [0.89 , 0.11 ],\n",
       "       [0.585, 0.415],\n",
       "       [0.65 , 0.35 ],\n",
       "       [0.68 , 0.32 ],\n",
       "       [0.335, 0.665],\n",
       "       [0.58 , 0.42 ],\n",
       "       [0.615, 0.385],\n",
       "       [0.305, 0.695],\n",
       "       [0.725, 0.275],\n",
       "       [0.39 , 0.61 ],\n",
       "       [0.465, 0.535],\n",
       "       [0.525, 0.475],\n",
       "       [0.575, 0.425],\n",
       "       [0.06 , 0.94 ],\n",
       "       [0.65 , 0.35 ],\n",
       "       [0.27 , 0.73 ],\n",
       "       [0.855, 0.145],\n",
       "       [0.585, 0.415],\n",
       "       [0.53 , 0.47 ],\n",
       "       [0.88 , 0.12 ],\n",
       "       [0.41 , 0.59 ],\n",
       "       [0.955, 0.045],\n",
       "       [0.905, 0.095],\n",
       "       [0.575, 0.425],\n",
       "       [0.47 , 0.53 ],\n",
       "       [0.795, 0.205],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.775, 0.225],\n",
       "       [0.125, 0.875],\n",
       "       [0.805, 0.195],\n",
       "       [0.365, 0.635],\n",
       "       [0.215, 0.785],\n",
       "       [0.945, 0.055],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.16 , 0.84 ],\n",
       "       [0.705, 0.295],\n",
       "       [0.615, 0.385],\n",
       "       [0.825, 0.175],\n",
       "       [0.69 , 0.31 ],\n",
       "       [0.16 , 0.84 ],\n",
       "       [0.235, 0.765],\n",
       "       [0.55 , 0.45 ],\n",
       "       [0.97 , 0.03 ],\n",
       "       [0.245, 0.755],\n",
       "       [0.23 , 0.77 ],\n",
       "       [0.345, 0.655],\n",
       "       [0.97 , 0.03 ],\n",
       "       [0.865, 0.135],\n",
       "       [0.655, 0.345],\n",
       "       [0.66 , 0.34 ],\n",
       "       [0.445, 0.555],\n",
       "       [0.95 , 0.05 ],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.69 , 0.31 ],\n",
       "       [0.34 , 0.66 ],\n",
       "       [0.32 , 0.68 ],\n",
       "       [0.825, 0.175],\n",
       "       [0.96 , 0.04 ],\n",
       "       [0.865, 0.135],\n",
       "       [0.83 , 0.17 ],\n",
       "       [0.915, 0.085],\n",
       "       [0.33 , 0.67 ],\n",
       "       [0.87 , 0.13 ],\n",
       "       [0.945, 0.055],\n",
       "       [0.43 , 0.57 ],\n",
       "       [0.935, 0.065],\n",
       "       [0.62 , 0.38 ],\n",
       "       [0.945, 0.055],\n",
       "       [0.945, 0.055],\n",
       "       [0.615, 0.385],\n",
       "       [0.63 , 0.37 ],\n",
       "       [0.985, 0.015],\n",
       "       [0.34 , 0.66 ],\n",
       "       [0.665, 0.335],\n",
       "       [0.79 , 0.21 ],\n",
       "       [0.37 , 0.63 ],\n",
       "       [0.97 , 0.03 ],\n",
       "       [0.485, 0.515],\n",
       "       [0.92 , 0.08 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(random_state=0,n_estimators=200,max_features=2,oob_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_proba=np.array(clf.predict_proba(X_test))\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:,1])\n",
    "auc = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08431491, 0.25003872, 0.09151941, 0.06804153, 0.0741019 ,\n",
       "       0.15800613, 0.13643191, 0.13754548])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08431491, 0.25003872, 0.09151941, 0.06804153, 0.0741019 ,\n",
       "       0.15800613, 0.13643191, 0.13754548])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the impurity-based feature importances of the forest\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "importances = clf.feature_importances_\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for feature, importance in zip(X_col, clf.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances = importances.sort_values(by='Gini-importance',ascending=False)\n",
    "importances.plot.barh(color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "{'C': 1000, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "clf=LogisticRegression(solver='liblinear')\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "penalties=['l1','l2']\n",
    "# create grid\n",
    "params = {\n",
    " 'C': C_param_range,\n",
    " 'penalty': penalties,\n",
    " }\n",
    "\n",
    "clf_grid = GridSearchCV(estimator = clf, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='roc_auc',n_jobs = -1)\n",
    "# Fit the model\n",
    "clf_grid.fit(X_train, y_train)\n",
    "# print results\n",
    "print(clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "clf=LogisticRegression(C=1000,penalty='l2',solver='liblinear')\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "5      501   336     194      A        W      282      421      25   750.0   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "5           A  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Hitters_Data.csv')\n",
    "df=df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "y = np.log(df.Salary)\n",
    "\n",
    "# Drop the column with the independent variable (Salary), and columns for which we created dummy variables\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis = 1).astype('float64')\n",
    "\n",
    "# Define the feature set X.\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4408.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5511.0</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
       "1    315.0   81.0    7.0  24.0  38.0   39.0   14.0  3449.0   835.0    69.0   \n",
       "2    479.0  130.0   18.0  66.0  72.0   76.0    3.0  1624.0   457.0    63.0   \n",
       "3    496.0  141.0   20.0  65.0  78.0   37.0   11.0  5628.0  1575.0   225.0   \n",
       "4    321.0   87.0   10.0  39.0  42.0   30.0    2.0   396.0   101.0    12.0   \n",
       "5    594.0  169.0    4.0  74.0  51.0   35.0   11.0  4408.0  1133.0    19.0   \n",
       "..     ...    ...    ...   ...   ...    ...    ...     ...     ...     ...   \n",
       "317  497.0  127.0    7.0  65.0  48.0   37.0    5.0  2703.0   806.0    32.0   \n",
       "318  492.0  136.0    5.0  76.0  50.0   94.0   12.0  5511.0  1511.0    39.0   \n",
       "319  475.0  126.0    3.0  61.0  43.0   52.0    6.0  1700.0   433.0     7.0   \n",
       "320  573.0  144.0    9.0  85.0  60.0   78.0    8.0  3198.0   857.0    97.0   \n",
       "321  631.0  170.0    9.0  77.0  44.0   31.0   11.0  4908.0  1457.0    30.0   \n",
       "\n",
       "     CRuns   CRBI  CWalks  PutOuts  Assists  Errors  League_N  Division_W  \\\n",
       "1    321.0  414.0   375.0    632.0     43.0    10.0         1           1   \n",
       "2    224.0  266.0   263.0    880.0     82.0    14.0         0           1   \n",
       "3    828.0  838.0   354.0    200.0     11.0     3.0         1           0   \n",
       "4     48.0   46.0    33.0    805.0     40.0     4.0         1           0   \n",
       "5    501.0  336.0   194.0    282.0    421.0    25.0         0           1   \n",
       "..     ...    ...     ...      ...      ...     ...       ...         ...   \n",
       "317  379.0  311.0   138.0    325.0      9.0     3.0         1           0   \n",
       "318  897.0  451.0   875.0    313.0    381.0    20.0         0           0   \n",
       "319  217.0   93.0   146.0     37.0    113.0     7.0         0           1   \n",
       "320  470.0  420.0   332.0   1314.0    131.0    12.0         0           0   \n",
       "321  775.0  357.0   249.0    408.0      4.0     3.0         0           1   \n",
       "\n",
       "     NewLeague_N  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  \n",
       "5              0  \n",
       "..           ...  \n",
       "317            1  \n",
       "318            0  \n",
       "319            0  \n",
       "320            0  \n",
       "321            0  \n",
       "\n",
       "[263 rows x 19 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_trainStandard = scaler.transform(X_train)\n",
    "X_testStandard = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76808384, -0.60470869,  0.20274045, ..., -1.        ,\n",
       "         0.99052111, -0.9626035 ],\n",
       "       [-1.06641053, -1.01143446, -1.3519827 , ..., -1.        ,\n",
       "        -1.0095696 , -0.9626035 ],\n",
       "       [ 0.67498477,  0.97700265,  0.32233454, ..., -1.        ,\n",
       "        -1.0095696 ,  1.03884933],\n",
       "       ...,\n",
       "       [-1.46880466, -1.44075611, -1.23238861, ..., -1.        ,\n",
       "        -1.0095696 , -0.9626035 ],\n",
       "       [ 0.23096366,  0.09576348, -0.99320043, ..., -1.        ,\n",
       "         0.99052111,  1.03884933],\n",
       "       [ 1.00106278,  0.95440677,  1.39868134, ...,  1.        ,\n",
       "        -1.0095696 ,  1.03884933]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testStandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "{'a__max_features': 3, 'a__n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "a=RandomForestRegressor(random_state=0)\n",
    "# number of trees in random forest\n",
    "n_estimators = [100,200,300,400,500,600]\n",
    "# number of features at every split\n",
    "max_features = [3,4,5,6,7]\n",
    "# create grid\n",
    "params = {\n",
    " 'a__n_estimators': n_estimators,\n",
    " 'a__max_features': max_features,\n",
    " }\n",
    "\n",
    "pipe = Pipeline([('scaler',preprocessing.StandardScaler()),('a', a)])\n",
    "\n",
    "# Random search of parameters\n",
    "clf_grid = GridSearchCV(estimator = pipe, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='neg_mean_squared_error',n_jobs = -1)\n",
    "# Fit the model\n",
    "clf_grid.fit(X_train, y_train)\n",
    "# print results\n",
    "print(clf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.15424688036594958\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestRegressor(random_state=0,n_estimators=300,max_features=3)\n",
    "clf.fit(X_trainStandard,y_train)\n",
    "y_pred=clf.predict(X_testStandard)\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=3, n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([('scaler', preprocessing.StandardScaler()),('Regressor',RandomForestRegressor())])\n",
    "\n",
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'Regressor': [Ridge()],\n",
    "                 'Regressor__alpha': np.logspace(-3, 1, 10)},\n",
    "                {'Regressor': [Lasso(max_iter = 10000)],\n",
    "                 'Regressor__alpha': np.logspace(-3, 1, 10)},\n",
    "                {'Regressor': [KNeighborsRegressor()],\n",
    "                 'Regressor__n_neighbors':[2,3,4,5,6]},\n",
    "                {'Regressor': [RandomForestRegressor(random_state=0)],\n",
    "                 'Regressor__n_estimators': [100, 200,300,400,500],\n",
    "                 'Regressor__max_features': [3,4,5,6,7]}]\n",
    "\n",
    "# Create grid search \n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0,scoring='neg_mean_squared_error')\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "# View best model\n",
    "best_model.best_estimator_.get_params()['Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.15424688036594958\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestRegressor(random_state=0,n_estimators=300,max_features=3)\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_trainStandard,y_train)\n",
    "y_pred=clf.predict(X_testStandard)\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
